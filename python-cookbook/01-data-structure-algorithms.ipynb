{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "# Data Structures and Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "1. [Unpacking a Sequence into Separate Variables](#1.1-Unpacking-a-Sequence-into-Separate-Variables)\n",
    "2. [Unpacking elements from Iterables of Arbitrary Length](#1.2-Unpacking-elements-from-Iterables-of-Arbitrary-Length)\n",
    "3. [Keeping the Last N Items](#1.3-Keeping-the-Last-N-Items)\n",
    "4. [Finding the Largest or Smallest N Items](#1.4-Finding-the-Largest-or-Smallest-N-Items)\n",
    "5. [Implementing a Priority Queue](#1.5-Implementing-a-Priority-Queue)\n",
    "6. [Mapping Keys to Multiple Values in a Dictionary](#1.6-Mapping-Keys-to-Multiple-Values-in-a-Dictionary)\n",
    "7. [Keeping Dictionaries in Order](#1.7-Keeping-Dictionaries-in-Order)\n",
    "8. [Calculating with Dictionaries](#1.8--Calculating-with-Dictionaries)\n",
    "9. [Finding Commonalities in Two Dictionaries](#1.9-Finding-Commonalities-in-Two-Dictionaries)\n",
    "10. [Removing Duplicates from a Sequence while Maintaining Order](#1.10-Removing-Duplicates-from-a-Sequence-while-Maintaining-Order)\n",
    "11. [Naming a Slice](#1.11-Naming-a-Slice)\n",
    "12. [Determining the Most Frequently Occurring Items in a Sequence](#1.12-Determining-the-Most-Frequently-Occurring-Items-in-a-Sequence)\n",
    "13. [Sorting a List of Dictionaries by a Common Key](#1.13-Sorting-a-List-of-Dictionaries-by-a-Common-Key)\n",
    "14. [Sorting Objects Without Native Comparison Support](#1.14-Sorting-Objects-Without-Native-Comparison-Support)\n",
    "15. [Group Records Together Based on a Field](#1.15-Group-Records-Together-Based-on-a-Field)\n",
    "16. [Filtering Sequence Elements](#1.16-Filtering-Sequence-Elements)\n",
    "17. [Extracting a Subset of a Dictionary](#1.17-Extracting-a-Subset-of-a-Dictionary)\n",
    "18. [Mapping Names to Sequence Elements](#1.18-Mapping-Names-to-Sequence-Elements)\n",
    "19. [Transforming and Reducing Data at the Same Time](#1.19-Transforming-and-Reducing-Data-at-the-Same-Time)\n",
    "20. [Combining Multiple Mappings into a Single Mapping](#1.20-Combining-Multiple-Mappings-into-a-Single-Mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Unpacking a Sequence into Separate Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to to unpack an N-element tuple or sequence into a collection of N variables.\n",
    "\n",
    "That can be done using simple assignment operation. The only requirement is that the number of variables and structure match the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (4, 5)\n",
    "a, b = p\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = 'damn you beauty'.split(' ')\n",
    "word1, word2, word3 = data\n",
    "\n",
    "stuff = ['some stuff happens', (2017, 7, 12)]\n",
    "event, (year, month, day) = stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Unpacking actually works with any Iterable object, not just tuples of lists. This includes strings, files, iterators, and generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = 'Hello'\n",
    "a, b, c, d, e = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When unpacking, if you want to discard certain values, you can just pick a throwaway variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2017, 7, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, date = stuff\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Unpacking elements from Iterables of Arbitrary Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to unpack N elements from an iterable, but the iterable may be longer than N elements, causing a \"too many values to unpack exception\".\n",
    "\n",
    "Python \"star expressions\" can be used to address this problem. For example, suppose you run a course and decide at the end of the semester that you're going to drop the first and last homework grades and only average the rest of them. A start expression makes it easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_first_last(grades):\n",
    "    first, *middle, last = grades\n",
    "    return avg(middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use case: suppose you have user records that consist of a name and email address, followed by an arbitrary number of phone numbers. You could unpack the records like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = ('Tu', 'tu@random.com', '773-555-1212', '267-694-9395')\n",
    "name, email, *phone_numbers = record\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['773-555-1212', '267-694-9395']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: It's worth noting that the `phone_numbers` variable will always be a list, regardless of how many elements are unpacked (including None). Thus, you won't have to worry the possibility of it not being a list or so.\n",
    "\n",
    "The starred variable can also be the first one in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 9, 8, 7, 6, 10, 23]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "*trailing, current = [10, 9, 8, 7, 6, 10, 23, 100]\n",
    "print(trailing)\n",
    "print(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also worth noting that the star syntax can be especially useful when iterating over a sequence of tuples of varying length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo 1 2\n",
      "bar hello\n",
      "foo 3 4\n"
     ]
    }
   ],
   "source": [
    "records = [\n",
    "    ('foo', 1, 2),\n",
    "    ('bar', 'hello'),\n",
    "    ('foo', 3, 4),\n",
    "]\n",
    "\n",
    "def do_foo(x, y):\n",
    "    print('foo', x, y)\n",
    "    \n",
    "def do_bar(s):\n",
    "    print('bar', s)\n",
    "    \n",
    "for tag, *args in records:\n",
    "    if tag == 'foo':\n",
    "        do_foo(*args)\n",
    "    elif tag == 'bar':\n",
    "        do_bar(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star unpacking can also be useful when combined with string processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nobody\n",
      "/var/empty\n",
      "['*', '-2', '-2', 'Unprivileged User']\n",
      "/usr/bin/false\n"
     ]
    }
   ],
   "source": [
    "line = 'nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false'\n",
    "uname, *fields, homedir, sh = line.split(':')\n",
    "print(uname)\n",
    "print(homedir)\n",
    "print(fields)\n",
    "print(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record = ('ACME', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Keeping the Last N Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to keep a limited history of the last few items seen during iteration or during some other kind of processing.\n",
    "\n",
    "Keeping a limited history is a perfect use for a `collections.deque`. For example, the following code performs a simple text match on a sequence of lines and yields the matching line along with the previous N lines of context when found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def search(lines, pattern, history=5):\n",
    "    previous_lines = deque(maxlen=history)\n",
    "    for line in lines:\n",
    "        if pattern in line:\n",
    "            yield line, previous_lines\n",
    "        previous_lines.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing code to search for items, it is common to use a generator function involving `yield`, as shown in this recipe's solution. This decouples the process of searching from the code that uses the results.\n",
    "\n",
    "Using `deque(maxlen=N)` creates a fixed-sized queue. When new items are added and the queue is full, the oldest item is automatically removed. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([1, 2, 3], maxlen=3)\n",
      "deque([2, 3, 4], maxlen=3)\n"
     ]
    }
   ],
   "source": [
    "q = deque(maxlen=3)\n",
    "q.append(1)\n",
    "q.append(2)\n",
    "q.append(3)\n",
    "print(q)\n",
    "q.append(4)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, a `dequeue` can be used whenever you need a simple queue structure. If you don't give a maximum size, you get an unbounded queue that lets you append and pop items on either end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = deque()\n",
    "q.append(1)\n",
    "q.append(2)\n",
    "q.append(3)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([4, 1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.appendleft(4)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([4, 1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.pop()\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([1, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.popleft()\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding or popping items from either end of a queue has O(1) complexity. This is unlike a list where inserting or removing items from the front of the list is O(N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Finding the Largest or Smallest N Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to make a list of the largest or smallest N items in a collection.\n",
    "\n",
    "The `heapq` module has two functions - `nlargest()` and `nsmallest()` - that do exactly what you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 37, 23]\n",
      "[-4, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "nums = [1, 8, 23, 2, 7, -4, 18, 23, 42, 37, 2]\n",
    "print(heapq.nlargest(3, nums))\n",
    "print(heapq.nsmallest(3, nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both functions also accept a key parameter that allows them to be used with more complicated data structures. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "portfolio = [\n",
    "    {'name': 'IBM', 'shares': 100, 'price': 91.1},\n",
    "    {'name': 'AAPL', 'shares': 50, 'price': 543.22},\n",
    "    {'name': 'FB', 'shares': 200, 'price': 21.09},\n",
    "    {'name': 'HPQ', 'shares': 35, 'price': 31.75},\n",
    "    {'name': 'YHOO', 'shares': 45, 'price': 16.35},\n",
    "    {'name': 'ACME', 'shares': 75, 'price': 115.65}\n",
    "]\n",
    "\n",
    "cheap = heapq.nsmallest(3, portfolio, key=lambda s: s['price'])\n",
    "expensive = heapq.nlargest(3, portfolio, key=lambda s: s['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'YHOO', 'shares': 45, 'price': 16.35}, {'name': 'FB', 'shares': 200, 'price': 21.09}, {'name': 'HPQ', 'shares': 35, 'price': 31.75}]\n",
      "[{'name': 'AAPL', 'shares': 50, 'price': 543.22}, {'name': 'ACME', 'shares': 75, 'price': 115.65}, {'name': 'IBM', 'shares': 100, 'price': 91.1}]\n"
     ]
    }
   ],
   "source": [
    "print(cheap)\n",
    "print(expensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underneath the covers, these functions work by first converting the data into a list where items are ordered as a heap. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]\n",
    "\n",
    "heap = list(nums)\n",
    "heapq.heapify(heap)\n",
    "heap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature of a heap is that `heap[0]` is always the smallest item. Moreover, subsequent items can be easily found using the `heapq.heappop()` method, which pops off the first item and replaces it with the next smallest item (an operation that requires O(logN) operations where N is the size of the heap). For example, to find the three smallest items, you would do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heapq.heappop(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heapq.heappop(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heapq.heappop(heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nlargest()` and `nsmallest()` functions are most appropriate if you are trying to find a relatively small number of items. If you are simply trying to find the single smallest or largest item (N=1), it is faster to use `min()` and `max()`. Similarly, if N is about the same size as the collection itself, it is usually faster to sort it first and take a slice (i.e., use `sorted(items)[:N]` or `sorted(items)[-N:]`). It should be noted that the actual implementation of `nlargest()` and `nsmallest()` is adaptive in how it operates and will carry out some of these optimizations on your behalf (e.g., using sorting if N is close to the same size as the input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Implementing a Priority Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to implement a queue that sorts items by a given priority and always returns the item with the highest priority on each pop operation.\n",
    "\n",
    "The following class uses the `heapq` module to implement a simple priority queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "\n",
    "class PriorityQueue(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._queue = []\n",
    "        self._index = 0\n",
    "        \n",
    "    def push(self, item, priority):\n",
    "        heapq.heappush(self._queue, (-priority, self._index, item))\n",
    "        self._index += 1\n",
    "        \n",
    "    def pop(self):\n",
    "        return heapq.heappop(self._queue)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pq = PriorityQueue()\n",
    "pq.push('foo', 1)\n",
    "pq.push('bar', 5)\n",
    "pq.push('spam', 4)\n",
    "pq.push('grok', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bar'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grok'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core of this recipe concerns the use of the `heapq` module. The functions `heapq.heappush()` and `heapq.heappop()` insert and remove items from a list `_queue` in a way such that the first item in the list has the smallest priority. The `heappop()` method always returns the **smallest** item, so that is the key to making the queue pop the correct items. Moreover, since the push and pop operations have O(log N) complexity where N is the number of items in the heap, they are fairly efficient even for fairly large values of N.\n",
    "\n",
    "In this recipe, the queue consists of the form `(-priority, index, item)`. The `priority` value is negated to get the queue to sort items from highest priority to lowest priority. This is opposite of the normal heap ordering, which sorts from lowest to highest.\n",
    "\n",
    "The role of the `index` variable is to properly order items with the same priority level. By keeping a constantly increasing index, the items will be sorted according to the order in which they were inserted.  However, the index also serves an important role in making the comparison operations work for items that have the same priority level in case two items cannot be compared.\n",
    "\n",
    "If you make `(priority, item)` tuples, they can be compared as long as the priorities are different. However, if two tuples with equal priorities are compared, the comparison fails as before.\n",
    "\n",
    "By introducing the extra index and making `(priority, index, item)` tuples, you avoid this problem entirely since no two tuples will ever have the same value for `index` (and Python never bothers to compare the remaining tuple values once the result of comparison can be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Mapping Keys to Multiple Values in a Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to make a dictionary that maps keys to more than one value (a so-called \"multidict\")\n",
    "\n",
    "A dictionary is a mapping where each key is mapped to a single value. If you want to map keys to multiple values, you need to store the multiple values in another container such as a list or set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [4, 5]\n",
    "}\n",
    "\n",
    "e = {\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of whether or not to use lists or sets depends on intended use. Use a list if you want to preserve the insertion order of item. Use a set if you want to eliminate duplicates (and don't care about the order).\n",
    "\n",
    "To easily construct such dictionaries, you can use `defaultdict` in the `collections` module. A feature of `defaultdict` is that it automatically initializes  the first value so you can simply focus on adding items. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'a': [1, 2], 'b': [4]})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(list)\n",
    "d['a'].append(1)\n",
    "d['a'].append(2)\n",
    "d['b'].append(4)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One caution with `defaultdict` is that it will automatically create dictionary entries for keys accessed later on (even if they aren't currently found in the dictionary). If you don't want this behavior, you might use `setdefault()` on an ordinary dictionary instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2], 'b': [4]}\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "d.setdefault('a', []).append(1)\n",
    "d.setdefault('a', []).append(2)\n",
    "d.setdefault('b', []).append(4)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it's a little unnatural - not to mention the fuct that it always creates a new instance of the initial value on each invocation (the empty list [] in the example).\n",
    "\n",
    "In principle, constructing a multivalued dictionary is simple. However, initialization of the first value can be messy if you try to do it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "pairs = [('a', 1), ('a', 2), ('b', 4)]\n",
    "for key, value in pairs:\n",
    "    if key not in d:\n",
    "        d[key] = []\n",
    "    d[key].append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a `defaultdict` simply leads to much cleaner code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "for key, value in pairs:\n",
    "    d[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Keeping Dictionaries in Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to create a dictionary, and you also want to control the order of items when iterating or serializing.\n",
    "\n",
    "To control the order of items in a dictionary, you can use an `OrderedDict` from the `collections` module. It exactly preserves the original insertion order of data when iterating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo 1\n",
      "bar 2\n",
      "spam 3\n",
      "grok 4\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "d = OrderedDict()\n",
    "d['foo'] = 1\n",
    "d['bar'] = 2\n",
    "d['spam'] = 3\n",
    "d['grok'] = 4\n",
    "\n",
    "for key in d:\n",
    "    print(key, d[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `OrderedDict` can be particularly useful when you want to build a mapping that you may want to later serialize or encode into a different format. For example, if you want to precisely control the order of fields appearing in a JSON encoding, first building the data in an `OrderedDict` will do the trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"foo\": 1, \"bar\": 2, \"spam\": 3, \"grok\": 4}'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `OrderedDict` internally maintains a doubly linked list that orders the keys according to insertion order. When a new item is first inserted, it is placed at the end of the list. Subsequent reassignment of an existing key doesn't change the order.\n",
    "\n",
    "Be aware that the size of an `OrderedDict` is more than twice as large as a normal dictionary due to the extra linked list that's created. Thus, if you are going to build a data structure involving a large number of `OrderedDict` instances (e.g., reading 100,000 lines of a CSV file into a list of `OrderedDict` instances), you would need to study the requirements of your application to determine if the benefits outweighed the extra memory overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8  Calculating with Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to perform various calculations (e.g. minimum value, maximum value, sorting. etc.) on a dictionary of data.\n",
    "\n",
    "Consider this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prices = {\n",
    "    'ACME': 45.23,\n",
    "    'AAPL': 612.78,\n",
    "    'IBM': 205.55,\n",
    "    'HPQ': 37.20,\n",
    "    'FB': 10.75\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform useful calculations on the dictionary contents, it is often useful to invert the keys and values of the dictionary using `zip()`. For example, here's how to find the min and max:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.75, 'FB')\n",
      "(612.78, 'AAPL')\n"
     ]
    }
   ],
   "source": [
    "min_price = min(zip(prices.values(), prices.keys()))\n",
    "max_price = max(zip(prices.values(), prices.keys()))\n",
    "\n",
    "print(min_price)\n",
    "print(max_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10.75, 'FB'), (37.2, 'HPQ'), (45.23, 'ACME'), (205.55, 'IBM'), (612.78, 'AAPL')]\n"
     ]
    }
   ],
   "source": [
    "prices_sorted = sorted(zip(prices.values(), prices.keys()))\n",
    "\n",
    "print(prices_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.75, 'FB')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e6dabd90a6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprices_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# be aware that zip() creates an iterator that can only be consumed once\n",
    "prices_names = zip(prices.values(), prices.keys())\n",
    "print(min(prices_names))\n",
    "print(max(prices_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know information about the corresponding keys (e.g., which stock has the lowest price?). YOu can get the key corresponding to the min or max value if you supply a key function to `min()` and `max()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(prices, key=lambda k: prices[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(prices, key=lambda k: prices[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, to get the minimum value, you'll need to perform an extra lookup step. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612.78"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices[max(prices, key=lambda k: prices[k])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution involving `zip()` solves the problem by \"inverting\" the dictionary into a sequence of `(value, key)` pairs. When performing comparisons on such tuples, the `value` element is compared first, followed by the `key`. This gives you exactly the behavior that you want and allows reductions and sorting to be easily performed on the dictionary contents using a single statement.\n",
    "\n",
    "It should be noted that in calculations involving `(value, key)` pairs, if multiple have the same value, the key will be used to determine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45.23, 'AAA')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = { 'AAA': 45.23, 'ZZZ': 45.23 }\n",
    "min(zip(prices.values(), prices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Finding Commonalities in Two Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to dictionaries and want to find out what they might have in common (same keys, same values, etc.).\n",
    "\n",
    "Consider two dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {\n",
    "    'x': 1,\n",
    "    'y': 2,\n",
    "    'z': 3\n",
    "}\n",
    "\n",
    "b = {\n",
    "    'w': 10,\n",
    "    'x': 11,\n",
    "    'y': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out what the two dictionaries have in common, simply perform common set operations using the `keys()` or `items()` methods. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x', 'y'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find keys in common\n",
    "a.keys() & b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find keys in a that are not in b\n",
    "a.keys() - b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('y', 2)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find (key, value) pairs in common\n",
    "a.items() & b.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These kinds of operations can also be used to alter or filter dictionary contents. For example, suppose you want to make a new dictionary with selected keys removed. Here is some example code to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1, 'y': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a new dictionary with certain key s removed\n",
    "c = {key: a[key] for key in a.keys() - {'z', 'w'}}\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keys()` and `items()` methods of a dictionary return keys-view object that exposes the key and items-view object consisting of `key, value` pairs. These objects support common set operations such as unions, intersections, and differences. Thus you don't need to convert them into sets.\n",
    "\n",
    "Although similar, the `values()` method does not support the set operations described in this recipe. In part, this is due to the fact that unlike keys, the items contained in a values view aren't guaranteed to be unique. This alone makes certain set operations of questionable utility. However, if you must perform such calculations, they can be accomplished by simply converting the values to a set first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Removing Duplicates from a Sequence while Maintaining Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to eliminate duplicate values in a sequence, but preserve the order of the remaining items.\n",
    "\n",
    "If the values in the sequence are hashable, the problem can be easily solved using a set and a generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dedupe(items):\n",
    "    seen = set()\n",
    "    for item in items:\n",
    "        if item not in seen:\n",
    "            yield item\n",
    "            seen.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 2, 9, 10]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example of how to use your function\n",
    "a = [1, 5, 2, 1, 9, 1, 5, 10]\n",
    "list(dedupe(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only works if the items in the sequence are hashable. If you are trying to eliminate duplicates in a sequence of unhashable types (such as `dict`s), you can make a slight change to this recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dedupe(items, key=None):\n",
    "    seen = set()\n",
    "    for item in items:\n",
    "        val = item if key is None else key(item)\n",
    "        if val not in seen:\n",
    "            yield item\n",
    "            seen.add(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 1, 'y': 2}, {'x': 1, 'y': 3}, {'x': 2, 'y': 4}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\n",
    "    {'x': 1, 'y': 2},\n",
    "    {'x': 1, 'y': 3},\n",
    "    {'x': 1, 'y': 2},\n",
    "    {'x': 2, 'y': 4}\n",
    "]\n",
    "\n",
    "list(dedupe(a, key=lambda d: (d['x'], d['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 1, 'y': 2}, {'x': 2, 'y': 4}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dedupe(a, key=lambda d: d['x']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latter solution also works nicely if you want to eliminate duplicates based on the value of a single field or attribute or a larger data structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all you want to do is eliminate duplicates, it is often easy enough to make a set. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 5, 9, 10}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([1, 5, 2, 1, 3, 9, 5, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this approach doesn't preserve any kind of ordering. So, the resulting data will be scrambled afterward. The solution shown avoids this.\n",
    "\n",
    "The use of a generator function in this recipe reflects the fact that you might want the function to be extremely general purpose - not necessarily tied directly to list processing. For example, if you want to read a file, eliminating duplicate lines, you could simply do this:\n",
    "\n",
    "```python\n",
    "with open(somefile, 'r') as f:\n",
    "    for line in dedupe(f):\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Naming a Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your program has become an unreadable mess of hardcoded slice indices and you want to clean it up.\n",
    "\n",
    "Suppose you have some code that is pulling specific data fields out of a record string with fixed fields (e.g., from a flat file or similar format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51325.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = '....................100          .......513.25     ..........'\n",
    "\n",
    "# avoid having a lot of mysterious hardcoded indices\n",
    "# and what you're doing becomes much clearer\n",
    "SHARES = slice(20, 32)\n",
    "PRICE = slice(40, 48)\n",
    "\n",
    "cost = int(record[SHARES]) * float(record[PRICE])\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a general rule, writing code with a lot of hardcoded index values leads to a readability and maintenance mess. For example, if you come back to the code a year later, you'll look at it and wonder what you were thinking when you wrote it. The solution shown is simply a way of more clearly stating what your code is actually doing.\n",
    "\n",
    "In general, the built-in `slice()` creates a slice object that can be used anywhere a slice is allowed. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [0, 1, 2, 3, 4, 5, 6]\n",
    "a = slice(2, 4)\n",
    "items[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 10, 11, 4, 5, 6]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[a] = [10, 11]\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 5, 6]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del items[a]\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even do start, stop, step with a `slice` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = slice(10, 50, 2)\n",
    "a.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also map a slice onto a sequence of a specific\n",
    "# size by using its indices(size) method\n",
    "# this returns a tuple (start, stop, step) where all values\n",
    "# have been suitably limited to fit within bounds (as to avoid\n",
    "# Index Error exceptions)\n",
    "s = \"HelloWorld\"\n",
    "a.indices(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(*a.indices(len(s))):\n",
    "    print(i)\n",
    "    print(s[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Determining the Most Frequently Occurring Items in a Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a sequence of items, and you'd like to determine the most frequently occurring items in the sequence.\n",
    "\n",
    "The `collections.Counter` class is designed for just such a problem. It even comes with a handy `most_common()` method that will give you the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eyes', 8), ('the', 5), ('look', 4)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = [\n",
    "   'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',\n",
    "   'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the',\n",
    "   'eyes', \"don't\", 'look', 'around', 'the', 'eyes', 'look', 'into',\n",
    "   'my', 'eyes', \"you're\", 'under'\n",
    "]\n",
    "\n",
    "word_counts = Counter(words)\n",
    "top_three = word_counts.most_common(3)\n",
    "top_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as input, Counter objects can be fed any sequence of hashsable input items\n",
    "# under cover, a Counter is a dictionary that maps the items to the number of\n",
    "# occurrences\n",
    "word_counts[\"not\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts[\"eyes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'are': 1,\n",
       "         'around': 2,\n",
       "         \"don't\": 1,\n",
       "         'eyes': 9,\n",
       "         'in': 1,\n",
       "         'into': 3,\n",
       "         'look': 4,\n",
       "         'looking': 1,\n",
       "         'my': 4,\n",
       "         'not': 2,\n",
       "         'the': 5,\n",
       "         'under': 1,\n",
       "         'why': 1,\n",
       "         'you': 1,\n",
       "         \"you're\": 1})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to increment the count manually, simply use\n",
    "# addition\n",
    "morewords = ['why', 'are', 'you', 'not', 'looking', 'in', 'my', 'eyes']\n",
    "for word in morewords:\n",
    "    word_counts[word] += 1\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'are': 3,\n",
       "         'around': 2,\n",
       "         \"don't\": 1,\n",
       "         'eyes': 11,\n",
       "         'in': 3,\n",
       "         'into': 3,\n",
       "         'look': 4,\n",
       "         'looking': 3,\n",
       "         'my': 6,\n",
       "         'not': 4,\n",
       "         'the': 5,\n",
       "         'under': 1,\n",
       "         'why': 3,\n",
       "         'you': 3,\n",
       "         \"you're\": 1})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternatively, you could use the update() method\n",
    "word_counts.update(morewords)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'eyes': 9, 'the': 5, 'look': 4, 'my': 4, 'into': 3, 'not': 2, 'around': 2, \"don't\": 1, \"you're\": 1, 'under': 1, 'why': 1, 'are': 1, 'you': 1, 'looking': 1, 'in': 1})\n",
      "Counter({'eyes': 7, 'the': 5, 'look': 4, 'into': 3, 'my': 2, 'around': 2, \"don't\": 1, \"you're\": 1, 'under': 1})\n"
     ]
    }
   ],
   "source": [
    "# we could also do mathematical operations\n",
    "a = Counter(words)\n",
    "b = Counter(morewords)\n",
    "\n",
    "print(a + b)\n",
    "print(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13 Sorting a List of Dictionaries by a Common Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a list of dictionaries and you would like to sort the entries according to one or more of the dictionary values.\n",
    "\n",
    "Sorting this type of structure is easy using the `operator` module's `itemgetter` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = [\n",
    "    {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003},\n",
    "    {'fname': 'David', 'lname': 'Beazley', 'uid': 1002},\n",
    "    {'fname': 'John', 'lname': 'Cleese', 'uid': 1001},\n",
    "    {'fname': 'Big', 'lname': 'Jones', 'uid': 1004}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's fairly easy to output these rows ordered by any of the fields common to all of the dictionaries. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fname': 'Big', 'lname': 'Jones', 'uid': 1004}, {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003}, {'fname': 'David', 'lname': 'Beazley', 'uid': 1002}, {'fname': 'John', 'lname': 'Cleese', 'uid': 1001}]\n",
      "[{'fname': 'John', 'lname': 'Cleese', 'uid': 1001}, {'fname': 'David', 'lname': 'Beazley', 'uid': 1002}, {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003}, {'fname': 'Big', 'lname': 'Jones', 'uid': 1004}]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "rows_by_fname = sorted(rows, key=itemgetter('fname'))\n",
    "rows_by_uid = sorted(rows, key=itemgetter('uid'))\n",
    "\n",
    "print(rows_by_fname)\n",
    "print(rows_by_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fname': 'David', 'lname': 'Beazley', 'uid': 1002},\n",
       " {'fname': 'John', 'lname': 'Cleese', 'uid': 1001},\n",
       " {'fname': 'Big', 'lname': 'Jones', 'uid': 1004},\n",
       " {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_by_lfname = sorted(rows, key=itemgetter('lname', 'fname'))\n",
    "rows_by_lfname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `rows` is passed to the built-in `sorted()` function, which accepts a keyword argument `key`. This argument is expected to be a callable that accepts a single item from `rows` as input and returns a value that will be used as the basis for sorting. The `itemgetter()` function creates just such a callable.\n",
    "\n",
    "The `operator.itemgetter()` function takes as arguments the lookup indices used to extract the desired values from the records in `rows`. It can be a dictionary key name, a numeric list element, or any value that can be fed to an object's `__getitem__()` method. If you give multiple indices to `itemgetter()`, the callable it produces will return a tuple with all of the elements in it, and `sorted()` will order the output according to the sorted order of the tuples. This can be useful if you want to simultaneously sort on multiple fields (such as last and first name, as shown in the example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sometimes labmda is used\n",
    "rows_by_fname_ = sorted(rows, key=lambda r: r['fname'])\n",
    "rows_by_lfname = sorted(rows, key=lambda r: (r['lname'], r['fname']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both work just fine, but the solution involving `itemgetter()` typically runs a bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': 'John', 'lname': 'Cleese', 'uid': 1001}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min and max can be applied\n",
    "min(rows, key=itemgetter('uid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': 'Big', 'lname': 'Jones', 'uid': 1004}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(rows, key=itemgetter('uid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 Sorting Objects Without Native Comparison Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to sort objects of the same class, but they don't natively support comparison operations.\n",
    "\n",
    "The built-in `sorted()` function takes a key argument that can be passed a callable that will return some value in the object that `sorted` will use to compare objects. For example, if you have a sequence of `User` instances in your application, and you want to sort them by their `user_id` attribute, you would supply a callable that takes a `User` instance as input and returns the `user_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[User(23), User(3), User(99)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, user_id):\n",
    "        self.user_id = user_id\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'User({self.user_id})'\n",
    "    \n",
    "users = [User(23), User(3), User(99)]\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[User(3), User(23), User(99)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(users, key=lambda u: u.user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[User(3), User(23), User(99)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instead of using lambda, an alternative approach\n",
    "# is to use operator.attrgetter()\n",
    "from operator import attrgetter\n",
    "sorted(users, key=attrgetter('user_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a matter of personal preference to use `lambda` or `attrgetter`. Similar to `itemgetter`, `attrgetter` is a tad bit faster and allows multiple fields to be extracted simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15 Group Records Together Based on a Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a sequence of dictionaries or instances and you want to iterate over the data in groups based on the value of a particular field, such as date.\n",
    "\n",
    "The `itertools.groupby()` function is particularly useful for grouping data together like this. To illustrate, suppose you have the following list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = [\n",
    "    {'address': '5412 N CLARK', 'date': '07/01/2012'},\n",
    "    {'address': '5148 N CLARK', 'date': '07/04/2012'},\n",
    "    {'address': '5800 E 58TH', 'date': '07/02/2012'},\n",
    "    {'address': '2122 N CLARK', 'date': '07/03/2012'},\n",
    "    {'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'},\n",
    "    {'address': '1060 W ADDISON', 'date': '07/02/2012'},\n",
    "    {'address': '4801 N BROADWAY', 'date': '07/01/2012'},\n",
    "    {'address': '1039 W GRANVILLE', 'date': '07/04/2012'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose you want to iterate over the data in chunks together grouped by date. To do this, first sort by the desired field (in this case, date) and the use `itertools.groupby()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/01/2012\n",
      "\t {'address': '5412 N CLARK', 'date': '07/01/2012'}\n",
      "\t {'address': '4801 N BROADWAY', 'date': '07/01/2012'}\n",
      "07/02/2012\n",
      "\t {'address': '5800 E 58TH', 'date': '07/02/2012'}\n",
      "\t {'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'}\n",
      "\t {'address': '1060 W ADDISON', 'date': '07/02/2012'}\n",
      "07/03/2012\n",
      "\t {'address': '2122 N CLARK', 'date': '07/03/2012'}\n",
      "07/04/2012\n",
      "\t {'address': '5148 N CLARK', 'date': '07/04/2012'}\n",
      "\t {'address': '1039 W GRANVILLE', 'date': '07/04/2012'}\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "# sort by the desired field first\n",
    "rows.sort(key=itemgetter('date'))\n",
    "\n",
    "# iterate in group\n",
    "for date, items in groupby(rows, key=itemgetter('date')):\n",
    "    print(date)\n",
    "    for i in items: print('\\t', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupby()` function works by scanning a sequence and finding sequential \"runs\" of identical values (or values returned by the given key function). On each iteration, it returns the value along with an iterator that produces all of the items in a group with the same value.\n",
    "\n",
    "An important preliminary step is sorting the data according to the field of interest. Since `groupby()` only examines consecutive items, failing to sort first won't group the records as you want.\n",
    "\n",
    "If your goal is to simply group the data together by dates into a large data structure that allows random access, you may have better luck using `defaultdict()` to build a multidict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'07/01/2012': [{'address': '5412 N CLARK', 'date': '07/01/2012'}, {'address': '4801 N BROADWAY', 'date': '07/01/2012'}], '07/02/2012': [{'address': '5800 E 58TH', 'date': '07/02/2012'}, {'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'}, {'address': '1060 W ADDISON', 'date': '07/02/2012'}], '07/03/2012': [{'address': '2122 N CLARK', 'date': '07/03/2012'}], '07/04/2012': [{'address': '5148 N CLARK', 'date': '07/04/2012'}, {'address': '1039 W GRANVILLE', 'date': '07/04/2012'}]})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rows_by_date = defaultdict(list)\n",
    "for row in rows:\n",
    "    rows_by_date[row['date']].append(row)\n",
    "    \n",
    "print(rows_by_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If memory is no concern, it may be faster to do this than to first sort the records and iterate using `groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.16 Filtering Sequence Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have data inside of a sequence, and need to extract values or reduce the sequence using some criteria.\n",
    "\n",
    "\n",
    "The easiest way to filter sequence data is often to use a list comprehension. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 10, 2, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = [1, 4, -5, 10, -7, 2, 3, -1]\n",
    "[n for n in mylist if n > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, -7, -1]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n for n in mylist if n < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One potential issue with list comprehension is that if the input is large it might produce a large result. If this is a concern, you can use generator expressions to produce the filtered values iteratively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x1071b5258>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = (n for n in mylist if n > 0)\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "10\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for x in pos: print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the filtering criteria is more complicated such as involving exception handling or some other tricky detail. For this, put the filtering code into its own function and use the built-in `filter()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '-3', '4', '5']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = ['1', '2', '-3', '-', '4', 'N/A', '5']\n",
    "\n",
    "def is_int(val):\n",
    "    try: x = int(val); return True\n",
    "    except ValueError: return False\n",
    "    \n",
    "ivals = list(filter(is_int, values))\n",
    "ivals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehension and generator expressions are often the easiest and most straightforward ways to filter simple data. They also have the added power to transform the data at the same time.\n",
    "\n",
    "Another notable tool is `itertools.compress()`, which takes an iterable and an accompanying Boolean selector sequence as input. As output, it gives you all of the items in the iterable where the corresponding element in the selector is True. This can be useful if you're trying to apply the results of filtering one sequence to another related sequence. For example, suppose you have the following two columns of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addresses = [\n",
    "    '5412 N CLARK',\n",
    "    '5148 N CLARK',\n",
    "    '5800 E 58TH',\n",
    "    '2122 N CLARK'\n",
    "    '5645 N RAVENSWOOD',\n",
    "    '1060 W ADDISON',\n",
    "    '4801 N BROADWAY',\n",
    "    '1039 W GRANVILLE',\n",
    "]\n",
    "\n",
    "counts = [0, 3, 10, 4, 1, 7, 6, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose you want to make a list of all addresses where the corresponding count value was greater than 5. Here's how you could do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, True, False, False, True, True, False]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import compress\n",
    "\n",
    "more5 = [n > 5 for n in counts]\n",
    "more5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5800 E 58TH', '4801 N BROADWAY', '1039 W GRANVILLE']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(compress(addresses, more5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key here is to create a sequence of Booleans that indicates which elements satisfy the desired condition. The `compress()` function then picks out the items corresponding to `True` values.\n",
    "\n",
    "Like `filter()`, `compress()` normally returns an iterator. Thus you need to use `list()` to make it a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.17 Extracting a Subset of a Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to make a dictionary which is a subset of another dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be easily achieved by using dictionary comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = {\n",
    "    'orange': 4.99,\n",
    "    'apple': 5.99,\n",
    "    'grape': 3.99,\n",
    "    'cherry': 6.99,\n",
    "    'banana': 4.49,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'orange': 4.99, 'apple': 5.99, 'cherry': 6.99, 'banana': 4.49} {'grape': 3.99, 'banana': 4.49}\n"
     ]
    }
   ],
   "source": [
    "# Make a dictionary of items with prices over $4\n",
    "p1 = {key:value for key, value in prices.items() if value > 4}\n",
    "\n",
    "# Make a dictionary of healthy items\n",
    "healthy_names = ['grape', 'banana']\n",
    "p2 = {key: value for key, value in prices.items() if key in healthy_names}\n",
    "\n",
    "print(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of what can be accomplished with dictionary comprehension might also be done by creating a sequence of tuples and passing them into `dict` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 5.99, 'banana': 4.49, 'cherry': 6.99, 'orange': 4.99}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((key, value) for key, value in prices.items() if value > 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That said, dictionary comprehension is usually clearer and runs faster. Another way of doing the second example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'banana': 4.49, 'grape': 3.99}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_names_set = {'grape', 'banana'}\n",
    "{key: prices[key] for key in prices.keys() & healthy_names_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.18 Mapping Names to Sequence Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have code that accesses elements in lists or tuples by position, but that makes the code hard to read. It'd be great if there is a way to be less dependent on position in the structure, by accessing the elements by name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`collections.namedtuple()` provides these benefits, while adding minimal overhead over using a normal `tuple` object. `collections.namedtuple()` is actually a factory method that returns a subclass of the standard Python `tuple` type. You feed it a type name, and the fields it should have, and it returns a class that you can instantiate, passing in values for the fields you've defined, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Subscriber = namedtuple('Subscriber', ['address', 'joined'])\n",
    "sub = Subscriber('Philly', '2018-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subscriber(address='Philly', joined='2018-02')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philly\n",
      "2018-02\n"
     ]
    }
   ],
   "source": [
    "print(sub.address)\n",
    "print(sub.joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although being a class of its own, an instance of`namedtuple` is actually interchangeble with a `tuple` and supports all of its operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Philly'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr, joined = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philly 2018-02\n"
     ]
    }
   ],
   "source": [
    "print(addr, joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A major use case of `namedtuple` is to decouple your code from the position of the elements it manipulates. For example, if you get back a list of tuples as a result of database query. Then it would for sure break your code if there is a new column in the database. Not so if you cast the returned `tuple` to `namedtuple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_1(records):\n",
    "    total = 0.0\n",
    "    for rec in records:\n",
    "        total += rec[1] * rec[2]\n",
    "    return total\n",
    "\n",
    "\n",
    "def compute_cost_2(records):\n",
    "    total = 0.0\n",
    "    for rec in records:\n",
    "        s = Stock(*rec)\n",
    "        total += s.shares * s.price\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally you can avoid the explicit conversion to `Stock` `namedtuple` if the `records` sequence in the example already contained such instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible use case of `namedtuple` is to replace dictionary, which takes more memory. However, a `namedtuple` is **immutable**, so keep that in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stock(name='AMZ', shares='30', price='50')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stock = namedtuple('Stock', ['name', 'shares', 'price'])\n",
    "s = Stock('AMZ', '30', '50')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8d8faccf94e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "s.shares = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do want to change, though, then `_replace` method will replace the attribute and generate a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stock(name='AMZ', shares=80, price='50')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s._replace(shares=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subtle and interesting use of `_replace()` is to have a \"prototype\" `tuple` containing default values and then use `_replace()` to create new tuples with new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock = namedtuple('Stock', ['name', 'shares', 'price', 'date', 'time'])\n",
    "\n",
    "# create a prototype stock\n",
    "prototype = Stock('', 0, 0.0, None, None)\n",
    "\n",
    "# function to convert a dictionary to a stock\n",
    "def dict_to_stock(s):\n",
    "    return prototype._replace(**s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'name': 'ACME', 'shares': 100, 'price': 123.45}\n",
    "b = {'name': 'HUBS', 'shares': 120, 'price': 111.25, 'date': '2018/02/25'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stock(name='ACME', shares=100, price=123.45, date=None, time=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_to_stock(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stock(name='HUBS', shares=120, price=111.25, date='2018/02/25', time=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_to_stock(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.19 Transforming and Reducing Data at the Same Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to execute some reducer function (`sum()`, `max()`, `min()`), but first need to transform or filter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very elegant way to combine data reduction and transformation is to use a generator-expression argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12559"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the sum of squares\n",
    "nums = [1, 2, 45, 100, 23]\n",
    "sum(x*x for x in nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are some iPython notebooks\n"
     ]
    }
   ],
   "source": [
    "# Some other examples\n",
    "import os\n",
    "\n",
    "# determine if there is any file that ends with\n",
    "# .ipynb inside the current directory\n",
    "files = os.listdir('.')\n",
    "if any(name.endswith('.ipynb') for name in files):\n",
    "    print('There are some iPython notebooks')\n",
    "else:\n",
    "    print('There is not!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AMZ,300,100.12'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output a tuple as CSV file\n",
    "\",\".join(str(x) for x in ('AMZ', 300, 100.12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data reduction across fields of a data structure\n",
    "portfolio = [\n",
    "    {'name': 'GOOG', 'shares': 50},\n",
    "    {'name': 'FB', 'shares': 75},\n",
    "    {'name': 'MSFT', 'shares': 87},\n",
    "    {'name': 'AMZN', 'shares': 100},\n",
    "]\n",
    "min(s['shares'] for s in portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution shows a subtle syntactic aspect of generator expressions when supplied as a single argument inside a function (i.e., you don't need repeated parentheses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12559\n",
      "12559\n"
     ]
    }
   ],
   "source": [
    "# These statements are the same\n",
    "print(sum(x*x for x in nums))\n",
    "print(sum((x*x for x in nums)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a generator is more efficient in terms of memory use. You could use list comprehension too, but that is fine when you have a small list. A large list would cause the program to create one in memory, only for that to be discarded later. The generator transforms the data iteratively and is therefore much more memory-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "{'name': 'GOOG', 'shares': 50}\n"
     ]
    }
   ],
   "source": [
    "# Also, min and max accept a key argument that is useful\n",
    "# where you might be inclined to use a generator as well\n",
    "from operator import itemgetter\n",
    "\n",
    "# origin -> returns 50\n",
    "print(min(s['shares'] for s in portfolio))\n",
    "\n",
    "# alternative -> returns {'name': 'GOOG', 'shares': 50}\n",
    "print(min(portfolio, key=itemgetter('shares')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.20 Combining Multiple Mappings into a Single Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have multiple dictionaries or mappings that you want to logically combine into a single mapping to perform certain operations, such as looking up values or checking for existing keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy way to this is to use the `ChainMap` class from `collections` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "\n",
    "# suppose you have two dictionaries\n",
    "a = {'x': 1, 'y': 2}\n",
    "b = {'y': 2, 'z': 3}\n",
    "\n",
    "c = ChainMap(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ChainMap` takes multiple mappings and make them logically appear as one. However, it doesn't literally merge them together. Instead, it simply keeps a list of the underlying mappings and redefines common dictionary operations to scan the list. Most of the operations will work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'z']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x', 1), ('y', 2), ('z', 3)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are duplicate keys, the value from the first mapping will get used. Thus the entry `c['z']` in the example would always refer to the value in the dictionary `a`, not the one in `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations that mutate the mapping\n",
    "# always affect the first mapping listed\n",
    "c['z'] = 10\n",
    "c['w'] = 40\n",
    "del c['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 40, 'y': 2, 'z': 10}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ChainMap` is particularly useful when working with scoped values such as variables in a programming language (i.e., globals, locals, etc.). In fact, there are methods that make this easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChainMap({'x': 1})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = ChainMap()\n",
    "values['x'] = 1\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new mapping\n",
    "values = values.new_child()\n",
    "values['x'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new mapping\n",
    "values = values.new_child()\n",
    "values['x'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChainMap({'x': 3}, {'x': 2}, {'x': 1})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discard last mapping\n",
    "values = values.parents\n",
    "values['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discard last mapping\n",
    "values = values.parents\n",
    "values['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChainMap({'x': 1})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative to `ChainMap`, you can use `update method`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 40, 'y': 2, 'z': 10}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = dict(b)\n",
    "merged.update(a)\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but it requires creating a completely separate dictionary object (or destructively alter one of the existing dictionaries). Also, if any of the original dictionaries mutate, the changes don't get reflected in the merged dictionary. A `ChainMap`, on the other hand **mutates the merged dictionary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
